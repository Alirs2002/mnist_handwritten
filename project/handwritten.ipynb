{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first phase we should import our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 15:51:57.492390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-10 15:51:57.827104: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-10 15:51:57.828928: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-10 15:51:59.172802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should consider variables for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = \"../dataset/train-images.idx3-ubyte\"\n",
    "y_train_path = \"../dataset/train-labels.idx1-ubyte\"\n",
    "x_test_path = \"../dataset/t10k-images.idx3-ubyte\"\n",
    "y_test_path = \"../dataset/t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy as idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = idx2.convert_from_file(x_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = idx2.convert_from_file(y_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = idx2.convert_from_file(x_test_path)\n",
    "y_test = idx2.convert_from_file(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see what is the scaling of our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min(),x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for better performance,we should normalize our data, i mean pixels should be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# by default,min max scaler does not do this operation inplace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.expand_dims(x_test,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7fcb862c20>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,10))\n",
    "plt.xlabel(y_train[0])\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def show_random(x_data,y_data):\n",
    "\n",
    "    # we call this function,for exploring our dataset,to see random images\n",
    "    \n",
    "    random_number = random.randint(0,len(x_data))\n",
    "    \n",
    "    plt.figure(figsize=(7,10))\n",
    "    plt.axis(True)\n",
    "    \n",
    "    plt.imshow(x_data[random_number])\n",
    "    plt.xlabel(y_data[random_number])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now,i think we should rescal our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train*(1./255.)\n",
    "x_test = x_test*(1./255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train,axis=-1)\n",
    "y_test = np.expand_dims(y_test,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should one hot encode our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = np.zeros(shape=(60000,10))\n",
    "y_test_encoded = np.zeros(shape=(10000,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       ...,\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [8.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.mean()\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 0., 4., ..., 5., 6., 8.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape((60000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)-1):\n",
    "    y_train_encoded[i][int(y_train[i])] = 1\n",
    "    \n",
    "for i in range(len(y_test)-1):\n",
    "    y_test_encoded[i][int(y_test[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model1.add(tf.keras.layers.Dense(8,activation=tf.keras.activations.relu))\n",
    "\n",
    "model1.add(tf.keras.layers.Dense(8,activation=tf.keras.activations.relu))\n",
    "\n",
    "model1.add(tf.keras.layers.Dense(10,activation=tf.keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "               metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we should fit the model\n",
    "\n",
    "for the first time,we just train it 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 - 3s - loss: 0.5688 - categorical_accuracy: 0.8301 - 3s/epoch - 1ms/step\n",
      "Epoch 2/50\n",
      "1875/1875 - 2s - loss: 0.3223 - categorical_accuracy: 0.9079 - 2s/epoch - 963us/step\n",
      "Epoch 3/50\n",
      "1875/1875 - 2s - loss: 0.2898 - categorical_accuracy: 0.9167 - 2s/epoch - 959us/step\n",
      "Epoch 4/50\n",
      "1875/1875 - 2s - loss: 0.2738 - categorical_accuracy: 0.9215 - 2s/epoch - 955us/step\n",
      "Epoch 5/50\n",
      "1875/1875 - 2s - loss: 0.2630 - categorical_accuracy: 0.9241 - 2s/epoch - 960us/step\n",
      "Epoch 6/50\n",
      "1875/1875 - 2s - loss: 0.2546 - categorical_accuracy: 0.9270 - 2s/epoch - 959us/step\n",
      "Epoch 7/50\n",
      "1875/1875 - 2s - loss: 0.2490 - categorical_accuracy: 0.9286 - 2s/epoch - 944us/step\n",
      "Epoch 8/50\n",
      "1875/1875 - 2s - loss: 0.2428 - categorical_accuracy: 0.9294 - 2s/epoch - 977us/step\n",
      "Epoch 9/50\n",
      "1875/1875 - 2s - loss: 0.2391 - categorical_accuracy: 0.9305 - 2s/epoch - 945us/step\n",
      "Epoch 10/50\n",
      "1875/1875 - 2s - loss: 0.2339 - categorical_accuracy: 0.9330 - 2s/epoch - 939us/step\n",
      "Epoch 11/50\n",
      "1875/1875 - 2s - loss: 0.2311 - categorical_accuracy: 0.9331 - 2s/epoch - 948us/step\n",
      "Epoch 12/50\n",
      "1875/1875 - 2s - loss: 0.2278 - categorical_accuracy: 0.9335 - 2s/epoch - 935us/step\n",
      "Epoch 13/50\n",
      "1875/1875 - 2s - loss: 0.2249 - categorical_accuracy: 0.9350 - 2s/epoch - 941us/step\n",
      "Epoch 14/50\n",
      "1875/1875 - 2s - loss: 0.2229 - categorical_accuracy: 0.9351 - 2s/epoch - 951us/step\n",
      "Epoch 15/50\n",
      "1875/1875 - 2s - loss: 0.2202 - categorical_accuracy: 0.9364 - 2s/epoch - 932us/step\n",
      "Epoch 16/50\n",
      "1875/1875 - 2s - loss: 0.2186 - categorical_accuracy: 0.9376 - 2s/epoch - 944us/step\n",
      "Epoch 17/50\n",
      "1875/1875 - 2s - loss: 0.2163 - categorical_accuracy: 0.9368 - 2s/epoch - 933us/step\n",
      "Epoch 18/50\n",
      "1875/1875 - 2s - loss: 0.2143 - categorical_accuracy: 0.9378 - 2s/epoch - 946us/step\n",
      "Epoch 19/50\n",
      "1875/1875 - 2s - loss: 0.2127 - categorical_accuracy: 0.9383 - 2s/epoch - 932us/step\n",
      "Epoch 20/50\n",
      "1875/1875 - 2s - loss: 0.2113 - categorical_accuracy: 0.9386 - 2s/epoch - 942us/step\n",
      "Epoch 21/50\n",
      "1875/1875 - 2s - loss: 0.2094 - categorical_accuracy: 0.9384 - 2s/epoch - 926us/step\n",
      "Epoch 22/50\n",
      "1875/1875 - 2s - loss: 0.2089 - categorical_accuracy: 0.9392 - 2s/epoch - 946us/step\n",
      "Epoch 23/50\n",
      "1875/1875 - 2s - loss: 0.2070 - categorical_accuracy: 0.9396 - 2s/epoch - 932us/step\n",
      "Epoch 24/50\n",
      "1875/1875 - 2s - loss: 0.2053 - categorical_accuracy: 0.9402 - 2s/epoch - 936us/step\n",
      "Epoch 25/50\n",
      "1875/1875 - 2s - loss: 0.2032 - categorical_accuracy: 0.9412 - 2s/epoch - 930us/step\n",
      "Epoch 26/50\n",
      "1875/1875 - 2s - loss: 0.2030 - categorical_accuracy: 0.9410 - 2s/epoch - 937us/step\n",
      "Epoch 27/50\n",
      "1875/1875 - 2s - loss: 0.2028 - categorical_accuracy: 0.9411 - 2s/epoch - 940us/step\n",
      "Epoch 28/50\n",
      "1875/1875 - 2s - loss: 0.2022 - categorical_accuracy: 0.9413 - 2s/epoch - 927us/step\n",
      "Epoch 29/50\n",
      "1875/1875 - 2s - loss: 0.2002 - categorical_accuracy: 0.9413 - 2s/epoch - 943us/step\n",
      "Epoch 30/50\n",
      "1875/1875 - 2s - loss: 0.1996 - categorical_accuracy: 0.9418 - 2s/epoch - 939us/step\n",
      "Epoch 31/50\n",
      "1875/1875 - 2s - loss: 0.1986 - categorical_accuracy: 0.9420 - 2s/epoch - 934us/step\n",
      "Epoch 32/50\n",
      "1875/1875 - 2s - loss: 0.1979 - categorical_accuracy: 0.9422 - 2s/epoch - 939us/step\n",
      "Epoch 33/50\n",
      "1875/1875 - 2s - loss: 0.1974 - categorical_accuracy: 0.9422 - 2s/epoch - 935us/step\n",
      "Epoch 34/50\n",
      "1875/1875 - 2s - loss: 0.1979 - categorical_accuracy: 0.9423 - 2s/epoch - 941us/step\n",
      "Epoch 35/50\n",
      "1875/1875 - 2s - loss: 0.1967 - categorical_accuracy: 0.9422 - 2s/epoch - 931us/step\n",
      "Epoch 36/50\n",
      "1875/1875 - 2s - loss: 0.1955 - categorical_accuracy: 0.9426 - 2s/epoch - 934us/step\n",
      "Epoch 37/50\n",
      "1875/1875 - 2s - loss: 0.1943 - categorical_accuracy: 0.9435 - 2s/epoch - 931us/step\n",
      "Epoch 38/50\n",
      "1875/1875 - 2s - loss: 0.1948 - categorical_accuracy: 0.9423 - 2s/epoch - 942us/step\n",
      "Epoch 39/50\n",
      "1875/1875 - 2s - loss: 0.1931 - categorical_accuracy: 0.9443 - 2s/epoch - 965us/step\n",
      "Epoch 40/50\n",
      "1875/1875 - 2s - loss: 0.1921 - categorical_accuracy: 0.9431 - 2s/epoch - 934us/step\n",
      "Epoch 41/50\n",
      "1875/1875 - 2s - loss: 0.1922 - categorical_accuracy: 0.9436 - 2s/epoch - 940us/step\n",
      "Epoch 42/50\n",
      "1875/1875 - 2s - loss: 0.1919 - categorical_accuracy: 0.9436 - 2s/epoch - 940us/step\n",
      "Epoch 43/50\n",
      "1875/1875 - 2s - loss: 0.1903 - categorical_accuracy: 0.9439 - 2s/epoch - 939us/step\n",
      "Epoch 44/50\n",
      "1875/1875 - 2s - loss: 0.1902 - categorical_accuracy: 0.9434 - 2s/epoch - 931us/step\n",
      "Epoch 45/50\n",
      "1875/1875 - 2s - loss: 0.1909 - categorical_accuracy: 0.9439 - 2s/epoch - 936us/step\n",
      "Epoch 46/50\n",
      "1875/1875 - 2s - loss: 0.1892 - categorical_accuracy: 0.9437 - 2s/epoch - 928us/step\n",
      "Epoch 47/50\n",
      "1875/1875 - 2s - loss: 0.1891 - categorical_accuracy: 0.9448 - 2s/epoch - 943us/step\n",
      "Epoch 48/50\n",
      "1875/1875 - 2s - loss: 0.1885 - categorical_accuracy: 0.9445 - 2s/epoch - 932us/step\n",
      "Epoch 49/50\n",
      "1875/1875 - 2s - loss: 0.1884 - categorical_accuracy: 0.9442 - 2s/epoch - 934us/step\n",
      "Epoch 50/50\n",
      "1875/1875 - 2s - loss: 0.1878 - categorical_accuracy: 0.9448 - 2s/epoch - 936us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7fcbabaaa0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train,y_train_encoded,\n",
    "           epochs=50,\n",
    "           batch_size=32,\n",
    "           verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 12.3391 - categorical_accuracy: 0.1009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.33906078338623, 0.10090000182390213]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test,y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it was fucking bad :(("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A we can see,we have huge overfit,in our fucking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(4,activation=tf.keras.activations.relu))\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(4,activation=tf.keras.activations.relu))\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(10,activation=tf.keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "               metrics=[tf.keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 1.1944 - categorical_accuracy: 0.5959 - 2s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "1875/1875 - 2s - loss: 0.7120 - categorical_accuracy: 0.7913 - 2s/epoch - 973us/step\n",
      "Epoch 3/10\n",
      "1875/1875 - 2s - loss: 0.6298 - categorical_accuracy: 0.8082 - 2s/epoch - 931us/step\n",
      "Epoch 4/10\n",
      "1875/1875 - 2s - loss: 0.5857 - categorical_accuracy: 0.8230 - 2s/epoch - 943us/step\n",
      "Epoch 5/10\n",
      "1875/1875 - 2s - loss: 0.5559 - categorical_accuracy: 0.8358 - 2s/epoch - 937us/step\n",
      "Epoch 6/10\n",
      "1875/1875 - 2s - loss: 0.5389 - categorical_accuracy: 0.8412 - 2s/epoch - 912us/step\n",
      "Epoch 7/10\n",
      "1875/1875 - 2s - loss: 0.5266 - categorical_accuracy: 0.8461 - 2s/epoch - 927us/step\n",
      "Epoch 8/10\n",
      "1875/1875 - 2s - loss: 0.5179 - categorical_accuracy: 0.8484 - 2s/epoch - 928us/step\n",
      "Epoch 9/10\n",
      "1875/1875 - 2s - loss: 0.5095 - categorical_accuracy: 0.8514 - 2s/epoch - 924us/step\n",
      "Epoch 10/10\n",
      "1875/1875 - 2s - loss: 0.5036 - categorical_accuracy: 0.8538 - 2s/epoch - 917us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7f406faec0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train_encoded,\n",
    "           epochs=10,\n",
    "           batch_size=32,\n",
    "           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 933us/step - loss: 9.1292 - categorical_accuracy: 0.1009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.129180908203125, 0.10090000182390213]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test,y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting this huge,mean there must be some problem in our fucking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random(x_test,y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encode incorrectly\n",
    "\n",
    "that was why it showed a huge awfullness in testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets train another model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential()\n",
    "\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(8,activation=tf.keras.activations.relu))\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(8,activation=tf.keras.activations.relu))\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(10,activation=tf.keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "               metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1875/1875 - 2s - loss: 0.7047 - categorical_accuracy: 0.7796 - 2s/epoch - 1ms/step\n",
      "Epoch 2/70\n",
      "1875/1875 - 2s - loss: 0.3591 - categorical_accuracy: 0.8965 - 2s/epoch - 934us/step\n",
      "Epoch 3/70\n",
      "1875/1875 - 2s - loss: 0.3148 - categorical_accuracy: 0.9079 - 2s/epoch - 940us/step\n",
      "Epoch 4/70\n",
      "1875/1875 - 2s - loss: 0.2937 - categorical_accuracy: 0.9146 - 2s/epoch - 925us/step\n",
      "Epoch 5/70\n",
      "1875/1875 - 2s - loss: 0.2757 - categorical_accuracy: 0.9202 - 2s/epoch - 931us/step\n",
      "Epoch 6/70\n",
      "1875/1875 - 2s - loss: 0.2622 - categorical_accuracy: 0.9236 - 2s/epoch - 921us/step\n",
      "Epoch 7/70\n",
      "1875/1875 - 2s - loss: 0.2529 - categorical_accuracy: 0.9269 - 2s/epoch - 928us/step\n",
      "Epoch 8/70\n",
      "1875/1875 - 2s - loss: 0.2456 - categorical_accuracy: 0.9295 - 2s/epoch - 919us/step\n",
      "Epoch 9/70\n",
      "1875/1875 - 2s - loss: 0.2397 - categorical_accuracy: 0.9291 - 2s/epoch - 951us/step\n",
      "Epoch 10/70\n",
      "1875/1875 - 2s - loss: 0.2339 - categorical_accuracy: 0.9322 - 2s/epoch - 1ms/step\n",
      "Epoch 11/70\n",
      "1875/1875 - 2s - loss: 0.2298 - categorical_accuracy: 0.9334 - 2s/epoch - 923us/step\n",
      "Epoch 12/70\n",
      "1875/1875 - 2s - loss: 0.2278 - categorical_accuracy: 0.9335 - 2s/epoch - 952us/step\n",
      "Epoch 13/70\n",
      "1875/1875 - 2s - loss: 0.2244 - categorical_accuracy: 0.9353 - 2s/epoch - 916us/step\n",
      "Epoch 14/70\n",
      "1875/1875 - 2s - loss: 0.2220 - categorical_accuracy: 0.9355 - 2s/epoch - 920us/step\n",
      "Epoch 15/70\n",
      "1875/1875 - 2s - loss: 0.2197 - categorical_accuracy: 0.9361 - 2s/epoch - 1ms/step\n",
      "Epoch 16/70\n",
      "1875/1875 - 2s - loss: 0.2178 - categorical_accuracy: 0.9359 - 2s/epoch - 967us/step\n",
      "Epoch 17/70\n",
      "1875/1875 - 2s - loss: 0.2164 - categorical_accuracy: 0.9365 - 2s/epoch - 935us/step\n",
      "Epoch 18/70\n",
      "1875/1875 - 2s - loss: 0.2153 - categorical_accuracy: 0.9369 - 2s/epoch - 941us/step\n",
      "Epoch 19/70\n",
      "1875/1875 - 2s - loss: 0.2125 - categorical_accuracy: 0.9379 - 2s/epoch - 1ms/step\n",
      "Epoch 20/70\n",
      "1875/1875 - 2s - loss: 0.2117 - categorical_accuracy: 0.9382 - 2s/epoch - 1ms/step\n",
      "Epoch 21/70\n",
      "1875/1875 - 2s - loss: 0.2102 - categorical_accuracy: 0.9384 - 2s/epoch - 932us/step\n",
      "Epoch 22/70\n",
      "1875/1875 - 2s - loss: 0.2090 - categorical_accuracy: 0.9388 - 2s/epoch - 923us/step\n",
      "Epoch 23/70\n",
      "1875/1875 - 2s - loss: 0.2077 - categorical_accuracy: 0.9388 - 2s/epoch - 921us/step\n",
      "Epoch 24/70\n",
      "1875/1875 - 2s - loss: 0.2074 - categorical_accuracy: 0.9397 - 2s/epoch - 947us/step\n",
      "Epoch 25/70\n",
      "1875/1875 - 2s - loss: 0.2066 - categorical_accuracy: 0.9388 - 2s/epoch - 919us/step\n",
      "Epoch 26/70\n",
      "1875/1875 - 2s - loss: 0.2047 - categorical_accuracy: 0.9395 - 2s/epoch - 926us/step\n",
      "Epoch 27/70\n",
      "1875/1875 - 2s - loss: 0.2040 - categorical_accuracy: 0.9395 - 2s/epoch - 987us/step\n",
      "Epoch 28/70\n",
      "1875/1875 - 2s - loss: 0.2035 - categorical_accuracy: 0.9394 - 2s/epoch - 912us/step\n",
      "Epoch 29/70\n",
      "1875/1875 - 2s - loss: 0.2025 - categorical_accuracy: 0.9403 - 2s/epoch - 912us/step\n",
      "Epoch 30/70\n",
      "1875/1875 - 2s - loss: 0.2020 - categorical_accuracy: 0.9408 - 2s/epoch - 912us/step\n",
      "Epoch 31/70\n",
      "1875/1875 - 2s - loss: 0.2018 - categorical_accuracy: 0.9402 - 2s/epoch - 898us/step\n",
      "Epoch 32/70\n",
      "1875/1875 - 2s - loss: 0.2007 - categorical_accuracy: 0.9411 - 2s/epoch - 920us/step\n",
      "Epoch 33/70\n",
      "1875/1875 - 2s - loss: 0.2000 - categorical_accuracy: 0.9402 - 2s/epoch - 907us/step\n",
      "Epoch 34/70\n",
      "1875/1875 - 2s - loss: 0.1997 - categorical_accuracy: 0.9414 - 2s/epoch - 905us/step\n",
      "Epoch 35/70\n",
      "1875/1875 - 2s - loss: 0.1995 - categorical_accuracy: 0.9417 - 2s/epoch - 910us/step\n",
      "Epoch 36/70\n",
      "1875/1875 - 2s - loss: 0.1980 - categorical_accuracy: 0.9414 - 2s/epoch - 904us/step\n",
      "Epoch 37/70\n",
      "1875/1875 - 2s - loss: 0.1984 - categorical_accuracy: 0.9412 - 2s/epoch - 903us/step\n",
      "Epoch 38/70\n",
      "1875/1875 - 2s - loss: 0.1979 - categorical_accuracy: 0.9416 - 2s/epoch - 900us/step\n",
      "Epoch 39/70\n",
      "1875/1875 - 2s - loss: 0.1960 - categorical_accuracy: 0.9420 - 2s/epoch - 907us/step\n",
      "Epoch 40/70\n",
      "1875/1875 - 2s - loss: 0.1950 - categorical_accuracy: 0.9414 - 2s/epoch - 911us/step\n",
      "Epoch 41/70\n",
      "1875/1875 - 2s - loss: 0.1953 - categorical_accuracy: 0.9420 - 2s/epoch - 907us/step\n",
      "Epoch 42/70\n",
      "1875/1875 - 2s - loss: 0.1949 - categorical_accuracy: 0.9412 - 2s/epoch - 904us/step\n",
      "Epoch 43/70\n",
      "1875/1875 - 2s - loss: 0.1939 - categorical_accuracy: 0.9424 - 2s/epoch - 903us/step\n",
      "Epoch 44/70\n",
      "1875/1875 - 2s - loss: 0.1933 - categorical_accuracy: 0.9427 - 2s/epoch - 916us/step\n",
      "Epoch 45/70\n",
      "1875/1875 - 2s - loss: 0.1931 - categorical_accuracy: 0.9424 - 2s/epoch - 912us/step\n",
      "Epoch 46/70\n",
      "1875/1875 - 2s - loss: 0.1932 - categorical_accuracy: 0.9423 - 2s/epoch - 910us/step\n",
      "Epoch 47/70\n",
      "1875/1875 - 2s - loss: 0.1932 - categorical_accuracy: 0.9425 - 2s/epoch - 913us/step\n",
      "Epoch 48/70\n",
      "1875/1875 - 2s - loss: 0.1921 - categorical_accuracy: 0.9428 - 2s/epoch - 917us/step\n",
      "Epoch 49/70\n",
      "1875/1875 - 2s - loss: 0.1914 - categorical_accuracy: 0.9427 - 2s/epoch - 909us/step\n",
      "Epoch 50/70\n",
      "1875/1875 - 2s - loss: 0.1906 - categorical_accuracy: 0.9434 - 2s/epoch - 902us/step\n",
      "Epoch 51/70\n",
      "1875/1875 - 2s - loss: 0.1913 - categorical_accuracy: 0.9423 - 2s/epoch - 902us/step\n",
      "Epoch 52/70\n",
      "1875/1875 - 2s - loss: 0.1904 - categorical_accuracy: 0.9432 - 2s/epoch - 908us/step\n",
      "Epoch 53/70\n",
      "1875/1875 - 2s - loss: 0.1904 - categorical_accuracy: 0.9422 - 2s/epoch - 907us/step\n",
      "Epoch 54/70\n",
      "1875/1875 - 2s - loss: 0.1902 - categorical_accuracy: 0.9431 - 2s/epoch - 916us/step\n",
      "Epoch 55/70\n",
      "1875/1875 - 2s - loss: 0.1896 - categorical_accuracy: 0.9424 - 2s/epoch - 913us/step\n",
      "Epoch 56/70\n",
      "1875/1875 - 2s - loss: 0.1886 - categorical_accuracy: 0.9433 - 2s/epoch - 930us/step\n",
      "Epoch 57/70\n",
      "1875/1875 - 2s - loss: 0.1883 - categorical_accuracy: 0.9439 - 2s/epoch - 922us/step\n",
      "Epoch 58/70\n",
      "1875/1875 - 2s - loss: 0.1883 - categorical_accuracy: 0.9442 - 2s/epoch - 900us/step\n",
      "Epoch 59/70\n",
      "1875/1875 - 2s - loss: 0.1874 - categorical_accuracy: 0.9438 - 2s/epoch - 905us/step\n",
      "Epoch 60/70\n",
      "1875/1875 - 2s - loss: 0.1885 - categorical_accuracy: 0.9441 - 2s/epoch - 903us/step\n",
      "Epoch 61/70\n",
      "1875/1875 - 2s - loss: 0.1873 - categorical_accuracy: 0.9441 - 2s/epoch - 909us/step\n",
      "Epoch 62/70\n",
      "1875/1875 - 2s - loss: 0.1867 - categorical_accuracy: 0.9441 - 2s/epoch - 904us/step\n",
      "Epoch 63/70\n",
      "1875/1875 - 2s - loss: 0.1867 - categorical_accuracy: 0.9438 - 2s/epoch - 949us/step\n",
      "Epoch 64/70\n",
      "1875/1875 - 2s - loss: 0.1865 - categorical_accuracy: 0.9432 - 2s/epoch - 935us/step\n",
      "Epoch 65/70\n",
      "1875/1875 - 2s - loss: 0.1867 - categorical_accuracy: 0.9441 - 2s/epoch - 906us/step\n",
      "Epoch 66/70\n",
      "1875/1875 - 2s - loss: 0.1863 - categorical_accuracy: 0.9440 - 2s/epoch - 912us/step\n",
      "Epoch 67/70\n",
      "1875/1875 - 2s - loss: 0.1860 - categorical_accuracy: 0.9444 - 2s/epoch - 900us/step\n",
      "Epoch 68/70\n",
      "1875/1875 - 2s - loss: 0.1866 - categorical_accuracy: 0.9444 - 2s/epoch - 933us/step\n",
      "Epoch 69/70\n",
      "1875/1875 - 2s - loss: 0.1846 - categorical_accuracy: 0.9450 - 2s/epoch - 934us/step\n",
      "Epoch 70/70\n",
      "1875/1875 - 2s - loss: 0.1856 - categorical_accuracy: 0.9443 - 2s/epoch - 916us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7f49caa1d0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train_encoded,\n",
    "           epochs=70,\n",
    "           batch_size=32,\n",
    "           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2465 - categorical_accuracy: 0.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24648787081241608, 0.9307000041007996]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test,y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see if we can improve our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = tf.keras.Sequential()\n",
    "\n",
    "model4.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model4.add(tf.keras.layers.Dense(10,activation=tf.keras.activations.relu))\n",
    "\n",
    "model4.add(tf.keras.layers.Dense(12,activation=tf.keras.activations.relu))\n",
    "\n",
    "model4.add(tf.keras.layers.Dense(10,activation=tf.keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "               metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1875/1875 - 2s - loss: 0.1857 - categorical_accuracy: 0.9435 - 2s/epoch - 969us/step\n",
      "Epoch 2/80\n",
      "1875/1875 - 2s - loss: 0.1845 - categorical_accuracy: 0.9449 - 2s/epoch - 939us/step\n",
      "Epoch 3/80\n",
      "1875/1875 - 2s - loss: 0.1845 - categorical_accuracy: 0.9445 - 2s/epoch - 957us/step\n",
      "Epoch 4/80\n",
      "1875/1875 - 2s - loss: 0.1853 - categorical_accuracy: 0.9447 - 2s/epoch - 959us/step\n",
      "Epoch 5/80\n",
      "1875/1875 - 2s - loss: 0.1834 - categorical_accuracy: 0.9446 - 2s/epoch - 997us/step\n",
      "Epoch 6/80\n",
      "1875/1875 - 2s - loss: 0.1838 - categorical_accuracy: 0.9447 - 2s/epoch - 922us/step\n",
      "Epoch 7/80\n",
      "1875/1875 - 2s - loss: 0.1843 - categorical_accuracy: 0.9452 - 2s/epoch - 957us/step\n",
      "Epoch 8/80\n",
      "1875/1875 - 2s - loss: 0.1836 - categorical_accuracy: 0.9448 - 2s/epoch - 932us/step\n",
      "Epoch 9/80\n",
      "1875/1875 - 2s - loss: 0.1835 - categorical_accuracy: 0.9444 - 2s/epoch - 929us/step\n",
      "Epoch 10/80\n",
      "1875/1875 - 2s - loss: 0.1830 - categorical_accuracy: 0.9447 - 2s/epoch - 917us/step\n",
      "Epoch 11/80\n",
      "1875/1875 - 2s - loss: 0.1836 - categorical_accuracy: 0.9443 - 2s/epoch - 951us/step\n",
      "Epoch 12/80\n",
      "1875/1875 - 2s - loss: 0.1832 - categorical_accuracy: 0.9445 - 2s/epoch - 922us/step\n",
      "Epoch 13/80\n",
      "1875/1875 - 2s - loss: 0.1832 - categorical_accuracy: 0.9457 - 2s/epoch - 949us/step\n",
      "Epoch 14/80\n",
      "1875/1875 - 2s - loss: 0.1828 - categorical_accuracy: 0.9448 - 2s/epoch - 946us/step\n",
      "Epoch 15/80\n",
      "1875/1875 - 2s - loss: 0.1823 - categorical_accuracy: 0.9456 - 2s/epoch - 919us/step\n",
      "Epoch 16/80\n",
      "1875/1875 - 2s - loss: 0.1818 - categorical_accuracy: 0.9452 - 2s/epoch - 921us/step\n",
      "Epoch 17/80\n",
      "1875/1875 - 2s - loss: 0.1816 - categorical_accuracy: 0.9453 - 2s/epoch - 921us/step\n",
      "Epoch 18/80\n",
      "1875/1875 - 2s - loss: 0.1825 - categorical_accuracy: 0.9455 - 2s/epoch - 913us/step\n",
      "Epoch 19/80\n",
      "1875/1875 - 2s - loss: 0.1811 - categorical_accuracy: 0.9458 - 2s/epoch - 915us/step\n",
      "Epoch 20/80\n",
      "1875/1875 - 2s - loss: 0.1821 - categorical_accuracy: 0.9448 - 2s/epoch - 923us/step\n",
      "Epoch 21/80\n",
      "1875/1875 - 2s - loss: 0.1817 - categorical_accuracy: 0.9461 - 2s/epoch - 935us/step\n",
      "Epoch 22/80\n",
      "1875/1875 - 2s - loss: 0.1819 - categorical_accuracy: 0.9450 - 2s/epoch - 910us/step\n",
      "Epoch 23/80\n",
      "1875/1875 - 2s - loss: 0.1817 - categorical_accuracy: 0.9453 - 2s/epoch - 913us/step\n",
      "Epoch 24/80\n",
      "1875/1875 - 2s - loss: 0.1809 - categorical_accuracy: 0.9459 - 2s/epoch - 910us/step\n",
      "Epoch 25/80\n",
      "1875/1875 - 2s - loss: 0.1808 - categorical_accuracy: 0.9457 - 2s/epoch - 907us/step\n",
      "Epoch 26/80\n",
      "1875/1875 - 2s - loss: 0.1809 - categorical_accuracy: 0.9460 - 2s/epoch - 908us/step\n",
      "Epoch 27/80\n",
      "1875/1875 - 2s - loss: 0.1807 - categorical_accuracy: 0.9459 - 2s/epoch - 906us/step\n",
      "Epoch 28/80\n",
      "1875/1875 - 2s - loss: 0.1816 - categorical_accuracy: 0.9452 - 2s/epoch - 909us/step\n",
      "Epoch 29/80\n",
      "1875/1875 - 2s - loss: 0.1803 - categorical_accuracy: 0.9460 - 2s/epoch - 905us/step\n",
      "Epoch 30/80\n",
      "1875/1875 - 2s - loss: 0.1801 - categorical_accuracy: 0.9460 - 2s/epoch - 915us/step\n",
      "Epoch 31/80\n",
      "1875/1875 - 2s - loss: 0.1798 - categorical_accuracy: 0.9464 - 2s/epoch - 908us/step\n",
      "Epoch 32/80\n",
      "1875/1875 - 2s - loss: 0.1805 - categorical_accuracy: 0.9464 - 2s/epoch - 907us/step\n",
      "Epoch 33/80\n",
      "1875/1875 - 2s - loss: 0.1796 - categorical_accuracy: 0.9472 - 2s/epoch - 913us/step\n",
      "Epoch 34/80\n",
      "1875/1875 - 2s - loss: 0.1803 - categorical_accuracy: 0.9461 - 2s/epoch - 906us/step\n",
      "Epoch 35/80\n",
      "1875/1875 - 2s - loss: 0.1794 - categorical_accuracy: 0.9463 - 2s/epoch - 1ms/step\n",
      "Epoch 36/80\n",
      "1875/1875 - 2s - loss: 0.1796 - categorical_accuracy: 0.9462 - 2s/epoch - 919us/step\n",
      "Epoch 37/80\n",
      "1875/1875 - 2s - loss: 0.1796 - categorical_accuracy: 0.9456 - 2s/epoch - 923us/step\n",
      "Epoch 38/80\n",
      "1875/1875 - 2s - loss: 0.1789 - categorical_accuracy: 0.9462 - 2s/epoch - 920us/step\n",
      "Epoch 39/80\n",
      "1875/1875 - 2s - loss: 0.1789 - categorical_accuracy: 0.9472 - 2s/epoch - 947us/step\n",
      "Epoch 40/80\n",
      "1875/1875 - 2s - loss: 0.1788 - categorical_accuracy: 0.9465 - 2s/epoch - 914us/step\n",
      "Epoch 41/80\n",
      "1875/1875 - 2s - loss: 0.1798 - categorical_accuracy: 0.9463 - 2s/epoch - 920us/step\n",
      "Epoch 42/80\n",
      "1875/1875 - 2s - loss: 0.1787 - categorical_accuracy: 0.9467 - 2s/epoch - 930us/step\n",
      "Epoch 43/80\n",
      "1875/1875 - 2s - loss: 0.1782 - categorical_accuracy: 0.9474 - 2s/epoch - 918us/step\n",
      "Epoch 44/80\n",
      "1875/1875 - 2s - loss: 0.1785 - categorical_accuracy: 0.9455 - 2s/epoch - 923us/step\n",
      "Epoch 45/80\n",
      "1875/1875 - 2s - loss: 0.1778 - categorical_accuracy: 0.9466 - 2s/epoch - 919us/step\n",
      "Epoch 46/80\n",
      "1875/1875 - 2s - loss: 0.1771 - categorical_accuracy: 0.9472 - 2s/epoch - 929us/step\n",
      "Epoch 47/80\n",
      "1875/1875 - 2s - loss: 0.1781 - categorical_accuracy: 0.9466 - 2s/epoch - 918us/step\n",
      "Epoch 48/80\n",
      "1875/1875 - 2s - loss: 0.1785 - categorical_accuracy: 0.9470 - 2s/epoch - 920us/step\n",
      "Epoch 49/80\n",
      "1875/1875 - 2s - loss: 0.1786 - categorical_accuracy: 0.9469 - 2s/epoch - 922us/step\n",
      "Epoch 50/80\n",
      "1875/1875 - 2s - loss: 0.1777 - categorical_accuracy: 0.9459 - 2s/epoch - 931us/step\n",
      "Epoch 51/80\n",
      "1875/1875 - 2s - loss: 0.1772 - categorical_accuracy: 0.9471 - 2s/epoch - 923us/step\n",
      "Epoch 52/80\n",
      "1875/1875 - 2s - loss: 0.1773 - categorical_accuracy: 0.9469 - 2s/epoch - 916us/step\n",
      "Epoch 53/80\n",
      "1875/1875 - 2s - loss: 0.1776 - categorical_accuracy: 0.9469 - 2s/epoch - 923us/step\n",
      "Epoch 54/80\n",
      "1875/1875 - 2s - loss: 0.1776 - categorical_accuracy: 0.9474 - 2s/epoch - 927us/step\n",
      "Epoch 55/80\n",
      "1875/1875 - 2s - loss: 0.1780 - categorical_accuracy: 0.9461 - 2s/epoch - 912us/step\n",
      "Epoch 56/80\n",
      "1875/1875 - 2s - loss: 0.1775 - categorical_accuracy: 0.9471 - 2s/epoch - 916us/step\n",
      "Epoch 57/80\n",
      "1875/1875 - 2s - loss: 0.1768 - categorical_accuracy: 0.9463 - 2s/epoch - 921us/step\n",
      "Epoch 58/80\n",
      "1875/1875 - 2s - loss: 0.1779 - categorical_accuracy: 0.9457 - 2s/epoch - 923us/step\n",
      "Epoch 59/80\n",
      "1875/1875 - 2s - loss: 0.1780 - categorical_accuracy: 0.9463 - 2s/epoch - 923us/step\n",
      "Epoch 60/80\n",
      "1875/1875 - 2s - loss: 0.1775 - categorical_accuracy: 0.9476 - 2s/epoch - 935us/step\n",
      "Epoch 61/80\n",
      "1875/1875 - 2s - loss: 0.1764 - categorical_accuracy: 0.9467 - 2s/epoch - 934us/step\n",
      "Epoch 62/80\n",
      "1875/1875 - 2s - loss: 0.1768 - categorical_accuracy: 0.9467 - 2s/epoch - 924us/step\n",
      "Epoch 63/80\n",
      "1875/1875 - 2s - loss: 0.1771 - categorical_accuracy: 0.9467 - 2s/epoch - 922us/step\n",
      "Epoch 64/80\n",
      "1875/1875 - 2s - loss: 0.1767 - categorical_accuracy: 0.9469 - 2s/epoch - 926us/step\n",
      "Epoch 65/80\n",
      "1875/1875 - 2s - loss: 0.1762 - categorical_accuracy: 0.9477 - 2s/epoch - 926us/step\n",
      "Epoch 66/80\n",
      "1875/1875 - 2s - loss: 0.1763 - categorical_accuracy: 0.9471 - 2s/epoch - 930us/step\n",
      "Epoch 67/80\n",
      "1875/1875 - 2s - loss: 0.1770 - categorical_accuracy: 0.9467 - 2s/epoch - 948us/step\n",
      "Epoch 68/80\n",
      "1875/1875 - 2s - loss: 0.1765 - categorical_accuracy: 0.9469 - 2s/epoch - 920us/step\n",
      "Epoch 69/80\n",
      "1875/1875 - 2s - loss: 0.1769 - categorical_accuracy: 0.9469 - 2s/epoch - 920us/step\n",
      "Epoch 70/80\n",
      "1875/1875 - 2s - loss: 0.1758 - categorical_accuracy: 0.9475 - 2s/epoch - 917us/step\n",
      "Epoch 71/80\n",
      "1875/1875 - 2s - loss: 0.1770 - categorical_accuracy: 0.9470 - 2s/epoch - 925us/step\n",
      "Epoch 72/80\n",
      "1875/1875 - 2s - loss: 0.1758 - categorical_accuracy: 0.9468 - 2s/epoch - 918us/step\n",
      "Epoch 73/80\n",
      "1875/1875 - 2s - loss: 0.1761 - categorical_accuracy: 0.9478 - 2s/epoch - 920us/step\n",
      "Epoch 74/80\n",
      "1875/1875 - 2s - loss: 0.1758 - categorical_accuracy: 0.9469 - 2s/epoch - 919us/step\n",
      "Epoch 75/80\n",
      "1875/1875 - 2s - loss: 0.1758 - categorical_accuracy: 0.9469 - 2s/epoch - 926us/step\n",
      "Epoch 76/80\n",
      "1875/1875 - 2s - loss: 0.1761 - categorical_accuracy: 0.9464 - 2s/epoch - 918us/step\n",
      "Epoch 77/80\n",
      "1875/1875 - 2s - loss: 0.1754 - categorical_accuracy: 0.9471 - 2s/epoch - 921us/step\n",
      "Epoch 78/80\n",
      "1875/1875 - 2s - loss: 0.1754 - categorical_accuracy: 0.9472 - 2s/epoch - 914us/step\n",
      "Epoch 79/80\n",
      "1875/1875 - 2s - loss: 0.1755 - categorical_accuracy: 0.9473 - 2s/epoch - 919us/step\n",
      "Epoch 80/80\n",
      "1875/1875 - 2s - loss: 0.1763 - categorical_accuracy: 0.9467 - 2s/epoch - 931us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7f51970a60>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train_encoded,\n",
    "           epochs=80,\n",
    "           batch_size=32,\n",
    "           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 2.3207 - categorical_accuracy: 0.0886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.320707082748413, 0.08860000222921371]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(x_test,y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see the best model,was model 3 \n",
    "\n",
    "model 4 was overfitting a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
